{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from importlib import reload \r\n",
    "import numpy as np\r\n",
    "import h5py\r\n",
    "from utils import *\r\n",
    "import time\r\n",
    "\r\n",
    "## Prior parameter ##\r\n",
    "nl_level = 10\r\n",
    "\r\n",
    "PRIOR = np.ones(4, dtype=[('MU', float, (4)), ('C', float, (4,4))])\r\n",
    "\r\n",
    "mu = np.ones([4,4])\r\n",
    "mu[0] = [8.5948, 8.0356, 0.9613, 9.5561]\r\n",
    "mu[1] = [8.4563, 7.8829, 0.9186, 9.3749]\r\n",
    "mu[2] = [8.6676, 8.0483, 1.0716, 9.7392]\r\n",
    "mu[3] = [8.4136, 7.8345, 0.7348, 9.1484]\r\n",
    "#print(mu)\r\n",
    "\r\n",
    "c = np.ones([4,4,4])\r\n",
    "c[0,:] = [[0.0037, 0.0027, 0.0008, 0.0000],\r\n",
    "            [0.0027, 0.0030, 0.0008, 0.0000],\r\n",
    "            [0.0008, 0.0008, 0.0003, 0.0000],\r\n",
    "            [0.0000, 0.0000, 0.0000, 0.0111]]\r\n",
    "\r\n",
    "c[1,:] = [[0.0032, 0.0028, 0.0011, 0.0000],\r\n",
    "            [0.0028, 0.0033, 0.0010, 0.0000],\r\n",
    "            [0.0011, 0.0010, 0.0006, 0.0000],\r\n",
    "            [0.0000, 0.0000, 0.0000, 0.0096]]\r\n",
    "\r\n",
    "c[2,:] = [[0.0023, 0.0016, 0.0008, 0.0000],\r\n",
    "            [0.0016, 0.0017, 0.0007, 0.0000],\r\n",
    "            [0.0008, 0.0007, 0.0006, 0.0000],\r\n",
    "            [0.0000, 0.0000, 0.0000, 0.0070]]\r\n",
    "\r\n",
    "c[3,:] = [[0.0008, 0.0005, 0.0003, 0.0000],\r\n",
    "            [0.0005, 0.0004, 0.0002, 0.0000],\r\n",
    "            [0.0003, 0.0002, 0.0003, 0.0000],\r\n",
    "            [0.0000, 0.0000, 0.0000, 0.0023]]\r\n",
    "#print(c)\r\n",
    "\r\n",
    "wavelet_new = [-1039.55055580727,\r\n",
    "            -4026.57620068033,\r\n",
    "            -8194.18572794536,\r\n",
    "            -11356.0387947636,\r\n",
    "            -11906.6435543803,\r\n",
    "            -10191.4389229172,\r\n",
    "            -8639.29324618705,\r\n",
    "            -10474.3682826362,\r\n",
    "            -17093.5087710456,\r\n",
    "            -25733.4288332681,\r\n",
    "            -29906.2345220425,\r\n",
    "            -23088.0727988944,\r\n",
    "            -3091.80943987738,\r\n",
    "            25306.1208726887,\r\n",
    "            51180.4184438887,\r\n",
    "            63288.5822013372,\r\n",
    "            53619.9099732780,\r\n",
    "            32940.2018555759,\r\n",
    "            11743.5370194762,\r\n",
    "            -3175.56289063239,\r\n",
    "            -10845.0261972202,\r\n",
    "            -13246.6910319655,\r\n",
    "            -12569.5536619989,\r\n",
    "            -10329.2514738468,\r\n",
    "            -7512.57465309683,\r\n",
    "            -5018.31852539635,\r\n",
    "            -3551.82629919458,\r\n",
    "            -3000.47980521376,\r\n",
    "            -2436.41725067266,\r\n",
    "            -1305.36051838710,\r\n",
    "            -346.558408174331]\r\n",
    "\r\n",
    "PRIOR['MU'] = mu\r\n",
    "PRIOR['C'] = c\r\n",
    "\r\n",
    "## Geracao do ensemble ##\r\n",
    "n = 48\r\n",
    "I = n\r\n",
    "J = 1\r\n",
    "signal2noise = 5\r\n",
    "v_fact = 0.1\r\n",
    "\r\n",
    "wavelet = np.array(wavelet_new)\r\n",
    "\r\n",
    "delta = np.zeros([31,1])\r\n",
    "delta[np.around(delta.shape[0]/2).astype(int)-1,0] = 1\r\n",
    "\r\n",
    "wavelet = lowPassFilter2(delta,4,40,60) - lowPassFilter2(delta,4,40,6)\r\n",
    "\r\n",
    "G = acoustic_foward_matrix(wavelet,I)\r\n",
    "\r\n",
    "#P = np.matrix('0.7 0.3 0 0; 0.3 0.7 0 0; 0.33 0.33 0.34 0; 0.1 0.1 0.1 0.7')\r\n",
    "P = np.matrix('0.7 0.3 0 0; 0.3 0.7 0 0; 0.33 0.33 0.34 0; 0.1 0.1 0.1 0.7')\r\n",
    "P = np.array(P)\r\n",
    "\r\n",
    "facies = simulate_markov_chain(P,n,3,1)\r\n",
    "print(facies.shape)\r\n",
    "mu, log_imp, seismic = facies_forward_model(facies, PRIOR, G, v_fact)\r\n",
    "\r\n",
    "noise = np.random.randn(I-1,1)\r\n",
    "noise = noise/np.std(noise)\r\n",
    "std_noise = np.std(seismic)/np.sqrt(signal2noise)\r\n",
    "noise = noise*std_noise\r\n",
    "seismic = seismic + noise.ravel()\r\n",
    "\r\n",
    "fig, axs = plt.subplots(4)\r\n",
    "fig.set_dpi(120)\r\n",
    "axs[0].imshow(facies.transpose(), aspect='auto')\r\n",
    "axs[1].plot(seismic)\r\n",
    "axs[2].plot(log_imp)\r\n",
    "axs[3].plot(wavelet)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gera modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.ndimage.filters import gaussian_filter\r\n",
    "\r\n",
    "Pver = np.array(np.matrix('0.7 0.3 0 0; 0.3 0.7 0 0; 0.33 0.33 0.34 0; 0.066 0.066 0.066 0.802'))\r\n",
    "Phor = np.array(np.matrix('0.4 0.4 0.1 0.1; 0.4 0.4 0.1 0.1; 0.1 0.1 0.6 0.2; 0.1 0.1 0.2 0.6'))\r\n",
    "\r\n",
    "#Simulation grid size\r\n",
    "\r\n",
    "I = 48\r\n",
    "J = 48\r\n",
    "initial_facies = 3\r\n",
    "\r\n",
    "prior_map = np.ones([I, J, 4])\r\n",
    "\r\n",
    "simulation = simulate_markov_2Dchain(Phor, Pver, prior_map, initial_facies)\r\n",
    "ss = gaussian_filter(simulation, sigma=[2, 1])\r\n",
    "st = simulation == 3\r\n",
    "ss[st] = 3\r\n",
    "ss = np.round(gaussian_filter(ss, sigma=[1.2, 1]))\r\n",
    "\r\n",
    "def facies_forward_model_2D(facies, PRIOR, G, v_fact):\r\n",
    "  seismics = []\r\n",
    "  impedances = []\r\n",
    "  for j in range(0,J):\r\n",
    "    mu, log_imp, seismic = facies_forward_model(facies[:,j], PRIOR, G, v_fact)\r\n",
    "    seismics.append(seismic)\r\n",
    "    impedances.append(log_imp)\r\n",
    "\r\n",
    "  seismics = np.array(seismics).transpose()\r\n",
    "  impedances = np.array(impedances).transpose()\r\n",
    "  return seismics, impedances\r\n",
    "\r\n",
    "seis, immp = facies_forward_model_2D(ss, PRIOR, G, v_fact)\r\n",
    "\r\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 6))\r\n",
    "axes[0].imshow(ss)\r\n",
    "axes[1].imshow(seis, cmap='gray')\r\n",
    "axes[2].imshow(immp)\r\n",
    "fig.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carrega o dataset em H5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "import h5py\r\n",
    "hf = h5py.File('data_set_2D.h5', 'r')\r\n",
    "X_bk = np.array(hf['X'])\r\n",
    "hf.close()\r\n",
    "print(X_bk.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4000, 48, 48)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normaliza o modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = np.copy(X_bk).astype(dtype='float32')\r\n",
    "X /= X.max()\r\n",
    "#X = (X - 0.5) / 0.5 # normalize (-1,1)\r\n",
    "X = np.expand_dims(X, axis=3)\r\n",
    "#X = np.transpose(X, axes=(0,2,1,3))\r\n",
    "#X = tf.keras.utils.to_categorical(X)\r\n",
    "print(X.shape)\r\n",
    "print(X_bk.min(),X_bk.max())\r\n",
    "print(X.min(),X.max())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output\r\n",
    "import tensorflow as tf\r\n",
    "import random\r\n",
    "\r\n",
    "class SampleImgs(tf.keras.callbacks.Callback):\r\n",
    "    def on_epoch_end(self, epoch, logs=None):\r\n",
    "        rnd = random.randint(0, X.shape[0]-1)\r\n",
    "        rnd_img = tf.expand_dims(X[rnd], axis=0)\r\n",
    "        z_mean, z_log_var, z = vae.encoder(rnd_img)\r\n",
    "        fig,axs = plt.subplots(1,3)\r\n",
    "        axs[0].imshow((rnd_img)[0])\r\n",
    "        axs[1].imshow(np.around(vae.decoder(z)[0]*3))\r\n",
    "        axs[2].hist(z.numpy().flatten())\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "class Sampling(tf.keras.layers.Layer):\r\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        z_mean, z_log_var = inputs\r\n",
    "        #print(z_mean.shape)\r\n",
    "        batch = tf.shape(z_mean)[0]\r\n",
    "        dim1 = tf.shape(z_mean)[1]\r\n",
    "        dim2 = tf.shape(z_mean)[2]\r\n",
    "        ch = tf.shape(z_mean)[3]\r\n",
    "        sh = (batch, dim1, dim2, ch)\r\n",
    "        #print(sh)\r\n",
    "        epsilon =  tf.random.normal(shape=sh)\r\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\r\n",
    "\r\n",
    "class VAE(tf.keras.Model):\r\n",
    "    def __init__(self, **kwargs):\r\n",
    "        super(VAE, self).__init__(**kwargs)\r\n",
    "\r\n",
    "        self.img_rows = 48\r\n",
    "        self.img_cols = 48\r\n",
    "        self.channels = 1\r\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\r\n",
    "        self.latent_dim = 12\r\n",
    "        self.latent_dim_shape = (self.latent_dim, self.latent_dim, self.channels)\r\n",
    "\r\n",
    "        self.encoder = self.build_encoder()\r\n",
    "        self.decoder = self.build_decoder()\r\n",
    "        \r\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\r\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\r\n",
    "            name=\"reconstruction_loss\"\r\n",
    "        )\r\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\r\n",
    "    \r\n",
    "    def build_encoder(self):\r\n",
    "\r\n",
    "        encoder_inputs = tf.keras.Input(shape=self.img_shape)\r\n",
    "        x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\r\n",
    "        x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\r\n",
    "        x = tf.keras.layers.Conv2D(128, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\r\n",
    "        #x = tf.keras.layers.Flatten()(x)\r\n",
    "        #x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\r\n",
    "        z_mean = tf.keras.layers.Conv2D(1, 1, strides=1, padding='same', name=\"z_mean\")(x)\r\n",
    "        z_log_var = tf.keras.layers.Conv2D(1, 1, strides=1, padding='same', name=\"z_log_var\")(x)\r\n",
    "        z = Sampling()([z_mean, z_log_var])\r\n",
    "        encoder = tf.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\r\n",
    "        encoder.summary()\r\n",
    "\r\n",
    "        return encoder\r\n",
    "\r\n",
    "    def build_decoder(self):\r\n",
    "\r\n",
    "        latent_inputs = tf.keras.Input(shape=self.latent_dim_shape)\r\n",
    "        #x = tf.keras.layers.Dense(6 * 6 * 64, activation=\"relu\")(latent_inputs)\r\n",
    "        #x = tf.keras.layers.Reshape((6, 6, 64))(x)\r\n",
    "        x = tf.keras.layers.Conv2D(32, 1, activation=\"relu\", strides=1, padding=\"same\")(latent_inputs)\r\n",
    "        x = tf.keras.layers.Conv2D(128, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\r\n",
    "        x = tf.keras.layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\r\n",
    "        x = tf.keras.layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\r\n",
    "        decoder_outputs = tf.keras.layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\r\n",
    "        decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\r\n",
    "        decoder.summary()\r\n",
    "\r\n",
    "        return decoder\r\n",
    "\r\n",
    "    @property\r\n",
    "    def metrics(self):\r\n",
    "        return [\r\n",
    "            self.total_loss_tracker,\r\n",
    "            self.reconstruction_loss_tracker,\r\n",
    "            self.kl_loss_tracker,\r\n",
    "        ]\r\n",
    "\r\n",
    "    def train_step(self, data):\r\n",
    "        clear_output(wait=False)\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            z_mean, z_log_var, z = self.encoder(data)\r\n",
    "            reconstruction = self.decoder(z)\r\n",
    "            reconstruction_loss = tf.reduce_mean(\r\n",
    "                tf.reduce_sum(\r\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\r\n",
    "                )\r\n",
    "            )\r\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\r\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\r\n",
    "            total_loss = reconstruction_loss + kl_loss\r\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\r\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\r\n",
    "        self.total_loss_tracker.update_state(total_loss)\r\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\r\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\r\n",
    "        return {\r\n",
    "            \"loss\": self.total_loss_tracker.result(),\r\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\r\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\r\n",
    "        }\r\n",
    "\r\n",
    "vae = VAE()\r\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\r\n",
    "vae.fit(X, epochs=30, batch_size=32, callbacks=[SampleImgs()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vae.fit(X, epochs=30, batch_size=32, callbacks=[SampleImgs()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imprime amostragens"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rn = tf.random.normal(shape=[2, vae.latent_dim, vae.latent_dim, 1], mean=0, stddev=1)\r\n",
    "#rn = tf.random.normal(shape=[2, cvae.latent_dim])\r\n",
    "\r\n",
    "plt.hist(rn.numpy().flatten())\r\n",
    "plt.show()\r\n",
    "\r\n",
    "plt.imshow(np.around(vae.decoder.predict(rn)*3)[0])\r\n",
    "plt.show()\r\n",
    "\r\n",
    "plt.imshow(np.around(X[50]*3))\r\n",
    "plt.title('true')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "ftrs = vae.encoder.predict(X[50:51])\r\n",
    "plt.hist(ftrs[0].flatten())\r\n",
    "plt.show()\r\n",
    "\r\n",
    "teste = ftrs[0].reshape((12, 12 ))\r\n",
    "plt.imshow(teste)\r\n",
    "plt.title('ftrs')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "plt.imshow(np.around(vae.decoder.predict(ftrs[-1])*3)[0])\r\n",
    "plt.title('vae')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# função"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def plt_ensamble(modelo_samples):\r\n",
    "    #w, h = int(math.sqrt(n_samples)), int(math.sqrt(n_samples))    \r\n",
    "    w = 1\r\n",
    "    h = 4\r\n",
    "    \r\n",
    "\r\n",
    "    fig, axs = plt.subplots(1,4, figsize=(8, 2), dpi=150)\r\n",
    "    plt.xticks(fontsize=6)\r\n",
    "    #gan_facies = tf.experimental.numpy.around(cvae.sample(eps=modelo_samples)*3)\r\n",
    "    idx = 0\r\n",
    "    for i in range(0,1):\r\n",
    "        for j in range(0,4):\r\n",
    "            axs[j].hist(tf.reshape(modelo_samples[idx], [modelo_samples.shape[1], modelo_samples.shape[2]]).numpy().flatten())\r\n",
    "            idx = idx + 1\r\n",
    "    #fig.tight_layout()\r\n",
    "    for axr in axs:\r\n",
    "        axr.xaxis.set_tick_params(labelsize=6)\r\n",
    "        axr.yaxis.set_tick_params(labelsize=6)\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "    fig, axs = plt.subplots(w,h, figsize=(8, 2), dpi=150)\r\n",
    "    #gan_facies = tf.experimental.numpy.around(cvae.sample(eps=modelo_samples)*3)\r\n",
    "    gan_facies = np.around(vae.decoder.predict(modelo_samples)*3)\r\n",
    "    idx = 0\r\n",
    "    for i in range(0,w):\r\n",
    "        for j in range(0,h):\r\n",
    "            axs[j].imshow(tf.reshape(gan_facies[idx], [n,n]))\r\n",
    "            axs[j].axis('off')\r\n",
    "            #axs[i,j].set_xticklabels([])\r\n",
    "            #axs[i,j].set_yticklabels([])\r\n",
    "            #axs[i,j].set_aspect('equal')\r\n",
    "            idx = idx + 1\r\n",
    "    #fig.tight_layout()\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "def plt_ensamble_dense(modelo_samples):\r\n",
    "    w, h = int(math.sqrt(n_samples)), int(math.sqrt(n_samples))    \r\n",
    "    fig, axs = plt.subplots(w,h, figsize=(15, 15), dpi=150)\r\n",
    "    gan_facies = tf.experimental.numpy.around(cvae_dense.sample(eps=modelo_samples[idx])*3)\r\n",
    "    idx = 0\r\n",
    "    for i in range(0,w):\r\n",
    "        for j in range(0,h):\r\n",
    "            axs[i,j].imshow(tf.reshape(gan_facies[idx], [n,n]))\r\n",
    "            axs[i,j].axis('off')\r\n",
    "            #axs[i,j].set_xticklabels([])\r\n",
    "            #axs[i,j].set_yticklabels([])\r\n",
    "            #axs[i,j].set_aspect('equal')\r\n",
    "            idx = idx + 1\r\n",
    "    #fig.tight_layout()\r\n",
    "    plt.show()\r\n",
    "#plt_ensamble(modelo_samples)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ESMDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.core.debugger import set_trace\r\n",
    "\r\n",
    "import time\r\n",
    "\r\n",
    "updts = 5\r\n",
    "ensize = 200\r\n",
    "cut_factor = 1\r\n",
    "\r\n",
    "G = tf.constant(acoustic_foward_matrix(wavelet,I), np.float32)\r\n",
    "\r\n",
    "ms = tf.Variable(tf.random.normal(shape=[ensize, vae.latent_dim * vae.latent_dim])*cut_factor)\r\n",
    "seis = tf.Variable(tf.zeros([ensize, G.shape[0]*G.shape[1]]))\r\n",
    "imps =  tf.Variable(tf.zeros([ensize, (G.shape[0]+1) * G.shape[1]]))\r\n",
    "\r\n",
    "### Sampling the reference model using the decoder\r\n",
    "rn = tf.random.normal(shape=[2, vae.latent_dim, vae.latent_dim, 1], mean=0, stddev=1)\r\n",
    "facies = np.around( vae.decoder.predict(rn)*3)[0]\r\n",
    "\r\n",
    "mr = tf.constant(facies.reshape(1,n,n,1), dtype=tf.float32)\r\n",
    "#mr_l = tf.constant(vae.encoder.predict(mr/3)[0])\r\n",
    "seis_exp_tmp, imp_exp_tmp = facies_forward_model_2D(mr.numpy().reshape(n,n),PRIOR,G.numpy(), v_fact)\r\n",
    "seis_exp = tf.constant(seis_exp_tmp.reshape(-1), dtype=tf.float32)\r\n",
    "imp_exp = tf.constant(imp_exp_tmp.reshape(-1), dtype=tf.float32)\r\n",
    "\r\n",
    "noise = np.random.randn((I-1)*J)\r\n",
    "noise = noise/np.std(noise)\r\n",
    "std_noise = np.std(seis_exp)/np.sqrt(signal2noise)\r\n",
    "noise = noise*std_noise\r\n",
    "#seis_exp = seis_exp + noise\r\n",
    "\r\n",
    "fig, axs = plt.subplots(1,3)\r\n",
    "fig.set_dpi(120)\r\n",
    "axs[0].imshow(mr.numpy().reshape(n,n))\r\n",
    "axs[1].imshow(seis_exp.numpy().reshape(n-1,n), cmap='gray')\r\n",
    "axs[2].imshow(imp_exp.numpy().reshape(n,n))\r\n",
    "plt.margins(0,0)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "C_d = std_noise**2*tf.eye(seis_exp.shape[0])\r\n",
    "\r\n",
    "start_time = time.time()\r\n",
    "\r\n",
    "alpha = tf.constant(updts, dtype=tf.float32)\r\n",
    "\r\n",
    "# Ensemble initialization\r\n",
    "\r\n",
    "for e in range(0,ensize):\r\n",
    "    lat = ms[e:e+1].numpy().reshape(1,vae.latent_dim, vae.latent_dim, 1)\r\n",
    "    facies = tf.Variable(np.around(vae.decoder.predict(lat)*3))\r\n",
    "    seis_exp_tmp, imp_exp_tmp = facies_forward_model_2D(np.array(facies.numpy().reshape(n,n)),PRIOR,G.numpy(), v_fact)\r\n",
    "    seis[e].assign(seis_exp_tmp.reshape(-1))\r\n",
    "    imps[e].assign(imp_exp_tmp.reshape(-1))\r\n",
    "\r\n",
    "print('Initial ensemble...')\r\n",
    "plt_ensamble(ms.numpy().reshape(ensize,vae.latent_dim, vae.latent_dim, 1))\r\n",
    "\r\n",
    "\r\n",
    "mean = tf.Variable(tf.reduce_mean(ms, axis=0))\r\n",
    "\r\n",
    "# Ensemble update\r\n",
    "start_time = time.time()\r\n",
    "# For update (u) in number of updates (updts)\r\n",
    "for u in range (1,updts):\r\n",
    "    print('Update ', u)\r\n",
    "    mean.assign(tf.reduce_mean(ms, 0))\r\n",
    "    \r\n",
    "    data_diff = seis.numpy() - np.tile(seis.numpy().mean(axis=0), (ensize,1) )\r\n",
    "    model_diff = ms.numpy() - np.tile(ms.numpy().mean(axis=0), (ensize,1) )\r\n",
    "\r\n",
    "    C_dd = tf.linalg.matmul(tf.transpose(data_diff), data_diff)/(ensize-1)\r\n",
    "    C_md = tf.linalg.matmul(tf.transpose(model_diff), data_diff)/(ensize-1)\r\n",
    "    \r\n",
    "    d_tio = seis_exp + tf.math.sqrt(alpha)*tf.random.normal(seis_exp.shape)*std_noise    \r\n",
    "    \r\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10, 6))\r\n",
    "    axs[0].imshow(seis_exp.numpy().reshape(n-1,n))\r\n",
    "    axs[0].set_title('d')\r\n",
    "    axs[1].imshow(d_tio.numpy().reshape(n-1,n))\r\n",
    "    axs[1].set_title('d_tio')\r\n",
    "    plt.show()\r\n",
    "            \r\n",
    "    fig, axs = plt.subplots(1,2,dpi=200)\r\n",
    "    axs[0].set_title('Cdd')\r\n",
    "    axs[1].set_title('Cmd')\r\n",
    "    axs[0].imshow(C_dd[:100,:100])\r\n",
    "    axs[1].imshow(C_md[:100,:])\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    \r\n",
    "    #K = tf.linalg.matmul(C_md, tf.linalg.pinv(C_dd + alpha*C_d, 0.001*tf.reduce_mean(tf.linalg.tensor_diag_part(C_d))))\r\n",
    "    K = tf.linalg.matmul( C_md, tf.linalg.inv(C_dd + alpha*C_d) )   \r\n",
    "\r\n",
    "    for e in range(0,ensize):     \r\n",
    "        # MODIFIED! Cada compoenente do ensemble precisa de um ruido diferente. \r\n",
    "        d_tio = seis_exp + tf.math.sqrt(alpha)*tf.random.normal(seis_exp.shape)*std_noise\r\n",
    "\r\n",
    "        dtio_dp = tf.reshape(d_tio - seis[e], [-1,1])\r\n",
    "        Ksum = tf.reshape(tf.linalg.matmul(K,dtio_dp), ms[e].shape)\r\n",
    "\r\n",
    "        ms[e].assign(ms[e] + Ksum)\r\n",
    "\r\n",
    "        facies = tf.Variable(np.around(vae.decoder.predict(ms[e:e+1].numpy().reshape(1,vae.latent_dim, vae.latent_dim, 1))*3))\r\n",
    "\r\n",
    "        seis_exp_tmp, imp_exp_tmp = facies_forward_model_2D(np.array(facies.numpy().reshape(n,n)),PRIOR,G.numpy(), v_fact)\r\n",
    "        seis[e].assign(seis_exp_tmp.reshape(-1))\r\n",
    "        imps[e].assign(imp_exp_tmp.reshape(-1))\r\n",
    "        \r\n",
    "\r\n",
    "    plt_ensamble(ms.numpy().reshape(ensize,vae.latent_dim, vae.latent_dim, 1))\r\n",
    "\r\n",
    "    mean_facies = tf.reduce_mean(vae.decoder.predict(ms.numpy().reshape(ensize, vae.latent_dim, vae.latent_dim, 1)), axis=0)\r\n",
    "\r\n",
    "    facies_es = tf.reshape(np.around(mean_facies*3), [n,n])\r\n",
    "    sismica_es, imp_es = facies_forward_model_2D(facies_es.numpy(),PRIOR,G.numpy(), v_fact)\r\n",
    "\r\n",
    "    fig, axs = plt.subplots(2,3, figsize=(10, 6))\r\n",
    "    axs[0,0].set_title('facies')\r\n",
    "    axs[0,1].set_title('seismic')\r\n",
    "    axs[0,2].set_title('impedance')\r\n",
    "    axs[1,0].set_title('facies vae')\r\n",
    "    axs[1,1].set_title('seismic vae')\r\n",
    "    axs[1,2].set_title('impedancia vae')\r\n",
    "    \r\n",
    "    axs[0,0].imshow(tf.reshape(mr, [n,n]))\r\n",
    "    axs[0,1].imshow(tf.reshape(seis_exp,[n-1,n]), cmap='gray')\r\n",
    "    axs[0,2].imshow(imp_exp.numpy().reshape(n,n))\r\n",
    "    axs[1,0].imshow(facies_es.numpy().reshape(n,n))\r\n",
    "    axs[1,1].imshow(sismica_es.reshape(n-1,n), cmap='gray')\r\n",
    "    axs[1,2].imshow(imp_es.reshape(n,n))\r\n",
    "    fig.tight_layout()\r\n",
    "    plt.show()\r\n",
    "    plt.close()\r\n",
    "\r\n",
    "print('Total time(s): ', time.time() - start_time)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}